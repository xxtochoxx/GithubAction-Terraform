2024.02.02 01:33:53 WARN  es[][o.e.t.ThreadPool] timer thread slept for [2h/7212014ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 03:35:57 WARN  es[][o.e.t.ThreadPool] timer thread slept for [2h/7293591ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 05:38:01 WARN  es[][o.e.t.ThreadPool] timer thread slept for [2h/7293935ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 06:38:59 WARN  es[][o.e.t.ThreadPool] timer thread slept for [30.8s/30891ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 06:39:00 WARN  es[][o.e.t.ThreadPool] timer thread slept for [30.8s/30890589241ns] on relative clock which is above the warn threshold of [5000ms]
2024.02.02 06:39:00 WARN  es[][o.e.t.ThreadPool] timer thread slept for [1h/3615310ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 06:39:20 WARN  es[][o.e.t.ThreadPool] timer thread slept for [6.6s/6632ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 06:39:20 WARN  es[][o.e.t.ThreadPool] timer thread slept for [6.6s/6632325629ns] on relative clock which is above the warn threshold of [5000ms]
2024.02.02 06:39:20 WARN  es[][o.e.t.ThreadPool] execution of [ReschedulingRunnable{runnable=org.elasticsearch.monitor.jvm.JvmGcMonitorService$1@2cc5f49f, interval=1s}] took [6632ms] which is above the warn threshold of [5000ms]
2024.02.02 07:40:15 WARN  es[][o.e.t.ThreadPool] timer thread slept for [1h/3645663ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 08:41:17 WARN  es[][o.e.t.ThreadPool] timer thread slept for [1h/3631879ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 10:43:25 WARN  es[][o.e.t.ThreadPool] timer thread slept for [2h/7296482ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 11:34:30 WARN  es[][o.e.t.ThreadPool] timer thread slept for [50.5m/3035596ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 12:45:44 WARN  es[][o.e.t.ThreadPool] timer thread slept for [1.1h/4243739ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 14:11:22 WARN  es[][o.e.t.ThreadPool] timer thread slept for [1.4h/5108704ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 14:22:53 WARN  es[][o.e.t.ThreadPool] timer thread slept for [11m/661136ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 14:23:52 WARN  es[][o.e.t.ThreadPool] absolute clock went backwards by [627ms/627ms] while timer thread was sleeping
2024.02.02 16:41:13 WARN  es[][o.e.t.ThreadPool] timer thread slept for [15.8m/950027ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 16:53:07 WARN  es[][o.e.t.ThreadPool] timer thread slept for [10.9m/654315ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 17:09:32 WARN  es[][o.e.t.ThreadPool] timer thread slept for [15.4m/925047ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 17:25:28 WARN  es[][o.e.t.ThreadPool] timer thread slept for [15.4m/925167ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 17:37:55 WARN  es[][o.e.t.ThreadPool] timer thread slept for [11.4m/687744ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 17:40:29 WARN  es[][o.e.t.ThreadPool] timer thread slept for [34.3s/34390ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 18:21:40 INFO  es[][o.e.n.Node] stopping ...
2024.02.02 18:21:40 INFO  es[][o.e.n.Node] stopped
2024.02.02 18:21:40 INFO  es[][o.e.n.Node] closing ...
2024.02.02 18:21:40 INFO  es[][o.e.n.Node] closed
2024.02.02 18:23:30 INFO  es[][o.e.n.Node] version[7.17.8], pid[27], build[default/tar/120eabe1c8a0cb2ae87cffc109a5b65d213e9df1/2022-12-02T17:33:09.727072865Z], OS[Linux/6.6.12-linuxkit/amd64], JVM[Eclipse Adoptium/OpenJDK 64-Bit Server VM/17.0.10/17.0.10+7]
2024.02.02 18:23:30 INFO  es[][o.e.n.Node] JVM home [/opt/java/openjdk]
2024.02.02 18:23:30 INFO  es[][o.e.n.Node] JVM arguments [-XX:+UseG1GC, -Djava.io.tmpdir=/opt/sonarqube/temp, -XX:ErrorFile=/opt/sonarqube/logs/es_hs_err_pid%p.log, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -Djna.tmpdir=/opt/sonarqube/temp, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=COMPAT, -Dcom.redhat.fips=false, -Xmx512m, -Xms512m, -XX:MaxDirectMemorySize=256m, -XX:+HeapDumpOnOutOfMemoryError, -Des.path.home=/opt/sonarqube/elasticsearch, -Des.path.conf=/opt/sonarqube/temp/conf/es, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=false]
2024.02.02 18:23:30 INFO  es[][o.e.p.PluginsService] loaded module [analysis-common]
2024.02.02 18:23:30 INFO  es[][o.e.p.PluginsService] loaded module [lang-painless]
2024.02.02 18:23:30 INFO  es[][o.e.p.PluginsService] loaded module [parent-join]
2024.02.02 18:23:30 INFO  es[][o.e.p.PluginsService] loaded module [reindex]
2024.02.02 18:23:30 INFO  es[][o.e.p.PluginsService] loaded module [transport-netty4]
2024.02.02 18:23:30 INFO  es[][o.e.p.PluginsService] no plugins loaded
2024.02.02 18:23:31 INFO  es[][o.e.e.NodeEnvironment] using [1] data paths, mounts [[/opt/sonarqube/data (/host_mark/Users)]], net usable_space [195.2gb], net total_space [465.6gb], types [fakeowner]
2024.02.02 18:23:31 INFO  es[][o.e.e.NodeEnvironment] heap size [512mb], compressed ordinary object pointers [true]
2024.02.02 18:23:32 INFO  es[][o.e.n.Node] node name [sonarqube], node ID [fCefQGYJT-izVOemomRVyg], cluster name [sonarqube], roles [data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
2024.02.02 18:23:44 INFO  es[][o.e.t.NettyAllocator] creating NettyAllocator with the following configs: [name=unpooled, suggested_max_allocation_size=256kb, factors={es.unsafe.use_unpooled_allocator=null, g1gc_enabled=true, g1gc_region_size=1mb, heap_size=512mb}]
2024.02.02 18:23:44 INFO  es[][o.e.i.r.RecoverySettings] using rate limit [40mb] with [default=40mb, read=0b, write=0b, max=0b]
2024.02.02 18:23:44 INFO  es[][o.e.d.DiscoveryModule] using discovery type [zen] and seed hosts providers [settings]
2024.02.02 18:23:45 INFO  es[][o.e.g.DanglingIndicesState] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
2024.02.02 18:23:45 INFO  es[][o.e.n.Node] initialized
2024.02.02 18:23:45 INFO  es[][o.e.n.Node] starting ...
2024.02.02 18:23:45 INFO  es[][o.e.t.TransportService] publish_address {127.0.0.1:44847}, bound_addresses {127.0.0.1:44847}
2024.02.02 18:23:47 INFO  es[][o.e.c.c.Coordinator] cluster UUID [F9G34RkAQDmCGklp35l31w]
2024.02.02 18:23:47 INFO  es[][o.e.c.s.MasterService] elected-as-master ([1] nodes joined)[{sonarqube}{fCefQGYJT-izVOemomRVyg}{UBGAnXV1S3upwBMKGxW5zw}{127.0.0.1}{127.0.0.1:44847}{cdfhimrsw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 8, version: 178, delta: master node changed {previous [], current [{sonarqube}{fCefQGYJT-izVOemomRVyg}{UBGAnXV1S3upwBMKGxW5zw}{127.0.0.1}{127.0.0.1:44847}{cdfhimrsw}]}
2024.02.02 18:23:47 INFO  es[][o.e.c.s.ClusterApplierService] master node changed {previous [], current [{sonarqube}{fCefQGYJT-izVOemomRVyg}{UBGAnXV1S3upwBMKGxW5zw}{127.0.0.1}{127.0.0.1:44847}{cdfhimrsw}]}, term: 8, version: 178, reason: Publication{term=8, version=178}
2024.02.02 18:23:48 INFO  es[][o.e.h.AbstractHttpServerTransport] publish_address {127.0.0.1:9001}, bound_addresses {127.0.0.1:9001}
2024.02.02 18:23:48 INFO  es[][o.e.n.Node] started
2024.02.02 18:23:48 INFO  es[][o.e.g.GatewayService] recovered [7] indices into cluster_state
2024.02.02 18:24:00 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[metadatas][0]]]).
2024.02.02 18:24:58 INFO  es[][o.e.m.j.JvmGcMonitorService] [gc][young][71][8] duration [722ms], collections [1]/[1.1s], total [722ms]/[889ms], memory [171.1mb]->[62.6mb]/[512mb], all_pools {[young] [116mb]->[0b]/[0b]}{[old] [47.6mb]->[47.6mb]/[512mb]}{[survivor] [7.5mb]->[15mb]/[0b]}
2024.02.02 18:24:58 WARN  es[][o.e.m.j.JvmGcMonitorService] [gc][71] overhead, spent [722ms] collecting in the last [1.1s]
2024.02.02 18:27:25 INFO  es[][o.e.n.Node] stopping ...
2024.02.02 18:27:25 INFO  es[][o.e.n.Node] stopped
2024.02.02 18:27:25 INFO  es[][o.e.n.Node] closing ...
2024.02.02 18:27:25 INFO  es[][o.e.n.Node] closed
2024.02.02 18:28:15 INFO  es[][o.e.n.Node] version[7.17.8], pid[27], build[default/tar/120eabe1c8a0cb2ae87cffc109a5b65d213e9df1/2022-12-02T17:33:09.727072865Z], OS[Linux/6.6.12-linuxkit/amd64], JVM[Eclipse Adoptium/OpenJDK 64-Bit Server VM/17.0.10/17.0.10+7]
2024.02.02 18:28:15 INFO  es[][o.e.n.Node] JVM home [/opt/java/openjdk]
2024.02.02 18:28:15 INFO  es[][o.e.n.Node] JVM arguments [-XX:+UseG1GC, -Djava.io.tmpdir=/opt/sonarqube/temp, -XX:ErrorFile=/opt/sonarqube/logs/es_hs_err_pid%p.log, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -Djna.tmpdir=/opt/sonarqube/temp, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j2.formatMsgNoLookups=true, -Djava.locale.providers=COMPAT, -Dcom.redhat.fips=false, -Xmx512m, -Xms512m, -XX:MaxDirectMemorySize=256m, -XX:+HeapDumpOnOutOfMemoryError, -Des.path.home=/opt/sonarqube/elasticsearch, -Des.path.conf=/opt/sonarqube/temp/conf/es, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=false]
2024.02.02 18:28:16 INFO  es[][o.e.p.PluginsService] loaded module [analysis-common]
2024.02.02 18:28:16 INFO  es[][o.e.p.PluginsService] loaded module [lang-painless]
2024.02.02 18:28:16 INFO  es[][o.e.p.PluginsService] loaded module [parent-join]
2024.02.02 18:28:16 INFO  es[][o.e.p.PluginsService] loaded module [reindex]
2024.02.02 18:28:16 INFO  es[][o.e.p.PluginsService] loaded module [transport-netty4]
2024.02.02 18:28:16 INFO  es[][o.e.p.PluginsService] no plugins loaded
2024.02.02 18:28:16 INFO  es[][o.e.e.NodeEnvironment] using [1] data paths, mounts [[/opt/sonarqube/data (/host_mark/Users)]], net usable_space [195.1gb], net total_space [465.6gb], types [fakeowner]
2024.02.02 18:28:16 INFO  es[][o.e.e.NodeEnvironment] heap size [512mb], compressed ordinary object pointers [true]
2024.02.02 18:28:16 INFO  es[][o.e.n.Node] node name [sonarqube], node ID [fCefQGYJT-izVOemomRVyg], cluster name [sonarqube], roles [data_frozen, master, remote_cluster_client, data, data_content, data_hot, data_warm, data_cold, ingest]
2024.02.02 18:28:20 INFO  es[][o.e.t.NettyAllocator] creating NettyAllocator with the following configs: [name=unpooled, suggested_max_allocation_size=256kb, factors={es.unsafe.use_unpooled_allocator=null, g1gc_enabled=true, g1gc_region_size=1mb, heap_size=512mb}]
2024.02.02 18:28:20 INFO  es[][o.e.i.r.RecoverySettings] using rate limit [40mb] with [default=40mb, read=0b, write=0b, max=0b]
2024.02.02 18:28:20 INFO  es[][o.e.d.DiscoveryModule] using discovery type [zen] and seed hosts providers [settings]
2024.02.02 18:28:21 INFO  es[][o.e.g.DanglingIndicesState] gateway.auto_import_dangling_indices is disabled, dangling indices will not be automatically detected or imported and must be managed manually
2024.02.02 18:28:21 INFO  es[][o.e.n.Node] initialized
2024.02.02 18:28:21 INFO  es[][o.e.n.Node] starting ...
2024.02.02 18:28:21 INFO  es[][o.e.t.TransportService] publish_address {127.0.0.1:32943}, bound_addresses {127.0.0.1:32943}
2024.02.02 18:28:21 INFO  es[][o.e.c.c.Coordinator] cluster UUID [F9G34RkAQDmCGklp35l31w]
2024.02.02 18:28:21 INFO  es[][o.e.c.s.MasterService] elected-as-master ([1] nodes joined)[{sonarqube}{fCefQGYJT-izVOemomRVyg}{iDrUJ2oeQuGB8OSFtDYxSA}{127.0.0.1}{127.0.0.1:32943}{cdfhimrsw} elect leader, _BECOME_MASTER_TASK_, _FINISH_ELECTION_], term: 9, version: 202, delta: master node changed {previous [], current [{sonarqube}{fCefQGYJT-izVOemomRVyg}{iDrUJ2oeQuGB8OSFtDYxSA}{127.0.0.1}{127.0.0.1:32943}{cdfhimrsw}]}
2024.02.02 18:28:21 INFO  es[][o.e.c.s.ClusterApplierService] master node changed {previous [], current [{sonarqube}{fCefQGYJT-izVOemomRVyg}{iDrUJ2oeQuGB8OSFtDYxSA}{127.0.0.1}{127.0.0.1:32943}{cdfhimrsw}]}, term: 9, version: 202, reason: Publication{term=9, version=202}
2024.02.02 18:28:22 INFO  es[][o.e.h.AbstractHttpServerTransport] publish_address {127.0.0.1:9001}, bound_addresses {127.0.0.1:9001}
2024.02.02 18:28:22 INFO  es[][o.e.n.Node] started
2024.02.02 18:28:22 INFO  es[][o.e.g.GatewayService] recovered [7] indices into cluster_state
2024.02.02 18:28:25 INFO  es[][o.e.c.r.a.AllocationService] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[metadatas][0]]]).
2024.02.02 20:05:31 WARN  es[][o.e.t.ThreadPool] timer thread slept for [50s/50033ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 21:09:17 WARN  es[][o.e.t.ThreadPool] timer thread slept for [1h/3795519ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 21:24:00 WARN  es[][o.e.t.ThreadPool] timer thread slept for [13.7m/824159ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 21:28:41 WARN  es[][o.e.t.ThreadPool] timer thread slept for [2.6m/161009ms] on absolute clock which is above the warn threshold of [5000ms]
2024.02.02 22:50:11 INFO  es[][o.e.m.j.JvmGcMonitorService] [gc][10861] overhead, spent [269ms] collecting in the last [1s]
